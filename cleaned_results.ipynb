{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanndevance/anaconda3/envs/new_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Example: moving a tensor to the MPS device\n",
    "tensor = torch.randn(2, 2).to(device)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata_videos(file_path):\n",
    "    return pd.read_csv(file_path).drop(columns='Unnamed: 0').dropna()\n",
    "\n",
    "def bart_classification(text, candidate_labels, multi_label=True, plot=False):\n",
    "    # Choose device based on availability (Apple Silicon or CUDA)\n",
    "    if torch.backends.mps.is_available():  # Apple Silicon GPUs\n",
    "        device = \"mps\"\n",
    "    elif torch.cuda.is_available():        # Other supported GPUs (CUDA)\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    # Initialize the zero-shot classifier with GPU support\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "    result = classifier(text, candidate_labels, multi_label=multi_label)\n",
    "    \n",
    "    scores, labels = result['scores'], result['labels']\n",
    "    sorted_pairs = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n",
    "    scores, labels = zip(*sorted_pairs)\n",
    "\n",
    "    max_score = scores[0]\n",
    "    threshold = max_score * 0.9\n",
    "    top_count = len([i for i, score in enumerate(scores) if score >= threshold])\n",
    "\n",
    "    if plot:\n",
    "        plot_scores(scores, labels)\n",
    "\n",
    "    if max_score < 0.3:\n",
    "        return [\"misc\"]\n",
    "    elif top_count == 1:\n",
    "        return [labels[0]]\n",
    "    elif top_count == 2 and multi_label:\n",
    "        return [labels[0], labels[1]]\n",
    "    elif top_count == 3 and multi_label:\n",
    "        return [labels[0], labels[1], labels[2]]\n",
    "    else:\n",
    "        return [\"uncertain\"]\n",
    "\n",
    "def plot_scores(scores, labels):\n",
    "    # Identify the index of the maximum score\n",
    "    max_index = scores.index(max(scores))\n",
    "\n",
    "    # Define colors: green for the max score, grey for others\n",
    "    colors = ['green' if i == max_index else 'grey' for i in range(len(labels))]\n",
    "\n",
    "    # Create the bar chart\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    bars = plt.bar(labels, scores, color=colors)\n",
    "\n",
    "    # Add score labels above each bar\n",
    "    for bar, score in zip(bars, scores):\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + 0.01,  # Slightly above the bar\n",
    "            f'{score:.2f}',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Probability of Each Label for the Video', fontsize=14)\n",
    "    plt.xlabel('Labels', fontsize=12)\n",
    "    plt.ylabel('Probability', fontsize=12)\n",
    "    plt.ylim(0, max(scores) + 0.1)  # Add some space on top for labels\n",
    "\n",
    "    # Optional: Rotate x-axis labels if they are too long\n",
    "    plt.xticks(rotation=20, ha='right')\n",
    "\n",
    "    # Show grid for better readability\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\\'################################################\\')\\nrandom.seed(352)\\nfor i in range(10):\\n    row = random.choice(df_education.index.to_list())\\n    title = df_education.loc[row, \\'title\\']\\n    tags = df_education.loc[row, \\'tags\\']\\n    combined_text = f\"{title} {tags.replace(\\',\\', \\', \\')}\"\\n    print(\\'Row:\\', row)\\n    print(\\'Title:\\', title)\\n    print(\\'Tags:\\', tags)\\n    purpose = bart_classification(combined_text, purpose_labels, multi_label=True, plot=False)\\n    print(\"--> Purpose:\", purpose)\\n    level = bart_classification(combined_text, level_labels, multi_label=False, plot=False)\\n    print(\"--> Level:  \", level)\\n    content = bart_classification(combined_text, content_labels, multi_label=True, plot=False)\\n    print(\"--> Content:\", content)\\n    print(\\'################################################\\')\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purpose_labels = [\n",
    "    \"lecture or academic course\", #exercise\n",
    "    #\"study-tips or test preparation\",\n",
    "    \"hacks\", \n",
    "    \"conference\",\n",
    "    \"tutorial or DIY\",\n",
    "    \"interview or Q&A or review\", #FIND BETTER\n",
    "    \"kids content\",\n",
    "    \"entertaining explanation or science popularization\",\n",
    "    \"documentary\" #research based\n",
    "]\n",
    "\n",
    "level_labels = [\n",
    "    \"beginner\",\n",
    "    \"intermediate\",\n",
    "    \"advanced\",\n",
    "]\n",
    "\n",
    "content_labels = [\n",
    "    \"science or technology\",\n",
    "    \"music or art\",\n",
    "    \"photography or videography or filmaking\",\n",
    "    \"gaming\",\n",
    "    \"chess or puzzles or logic\", #riddles\n",
    "    \"religion or spirituality\",\n",
    "    \"phylosophy or ethics\",\n",
    "    \"history or politics\",\n",
    "    \"economics or business\",\n",
    "    \"financial education\",\n",
    "    \"cryptocurrency\",\n",
    "    \"food or cooking\",\n",
    "    \"sport\",\n",
    "    \"health or medicine\",\n",
    "    \"travel\",\n",
    "    \"motivational or personal development\",\n",
    "    \"home repair or renovation\",  \n",
    "    \"beauty or fashion\",\n",
    "    \"programming tools or coding\",\n",
    "    \"foreign language\",\n",
    "    \"sociology or culture\",\n",
    "    \"psychology\",\n",
    "    \"climate or environment\",\n",
    "    \"wildlife or animals or nature\" #segment?\n",
    "]\n",
    "\"\"\"\n",
    "print('################################################')\n",
    "random.seed(352)\n",
    "for i in range(10):\n",
    "    row = random.choice(df_education.index.to_list())\n",
    "    title = df_education.loc[row, 'title']\n",
    "    tags = df_education.loc[row, 'tags']\n",
    "    combined_text = f\"{title} {tags.replace(',', ', ')}\"\n",
    "    print('Row:', row)\n",
    "    print('Title:', title)\n",
    "    print('Tags:', tags)\n",
    "    purpose = bart_classification(combined_text, purpose_labels, multi_label=True, plot=False)\n",
    "    print(\"--> Purpose:\", purpose)\n",
    "    level = bart_classification(combined_text, level_labels, multi_label=False, plot=False)\n",
    "    print(\"--> Level:  \", level)\n",
    "    content = bart_classification(combined_text, content_labels, multi_label=True, plot=False)\n",
    "    print(\"--> Content:\", content)\n",
    "    print('################################################')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:19.304589\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             oG4rYTF7WYQ\n",
      "duration                                                        70\n",
      "like_count                                                     8.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            That's It We Are Ready To Bond - Kabbalah Mome...\n",
      "upload_date                                    2010-11-17 00:00:00\n",
      "view_count                                                   444.0\n",
      "Name: 0, dtype: object\n",
      "Processing row 1:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:19.963060\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             Psiklp-WC4k\n",
      "duration                                                        72\n",
      "like_count                                                     2.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            Advancing Towards The Goal - Kabbalah Moments ...\n",
      "upload_date                                    2010-11-17 00:00:00\n",
      "view_count                                                   255.0\n",
      "Name: 1, dtype: object\n",
      "Processing row 2:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:20.570946\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             4PAUpgXDYWg\n",
      "duration                                                       127\n",
      "like_count                                                     1.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            A Cry To The Creator - Kabbalah Moments - Nove...\n",
      "upload_date                                    2010-11-17 00:00:00\n",
      "view_count                                                   214.0\n",
      "Name: 2, dtype: object\n",
      "Processing row 3:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:21.242292\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             DROFMmWO_7k\n",
      "duration                                                       137\n",
      "like_count                                                     1.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            We Found Out At The Convention - Kabbalah Mome...\n",
      "upload_date                                    2010-11-16 00:00:00\n",
      "view_count                                                   200.0\n",
      "Name: 3, dtype: object\n",
      "Processing row 4:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:21.869033\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             T54qFHPiPtY\n",
      "duration                                                       212\n",
      "like_count                                                     4.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            Revealing The Wall - Kabbalah Moments - Novemb...\n",
      "upload_date                                    2010-11-16 00:00:00\n",
      "view_count                                                   230.0\n",
      "Name: 4, dtype: object\n",
      "Processing row 5:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:22.448967\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             Y9srqgkc5e8\n",
      "duration                                                       121\n",
      "like_count                                                     1.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            Break Down The Wall - Kabbalah Moments - Novem...\n",
      "upload_date                                    2010-11-16 00:00:00\n",
      "view_count                                                   221.0\n",
      "Name: 5, dtype: object\n",
      "Processing row 6:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:23.156542\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  1.0\n",
      "display_id                                             -YafF9NkYQg\n",
      "duration                                                        96\n",
      "like_count                                                     6.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            Sacrifice In Kabbalah - Kabbalah Moments - Nov...\n",
      "upload_date                                    2010-11-16 00:00:00\n",
      "view_count                                                   492.0\n",
      "Name: 6, dtype: object\n",
      "Processing row 7:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:24.338451\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             IbN4PvU3XJU\n",
      "duration                                                       116\n",
      "like_count                                                     5.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            True Connection - Kabbalah Moments - November ...\n",
      "upload_date                                    2010-11-15 00:00:00\n",
      "view_count                                                   332.0\n",
      "Name: 7, dtype: object\n",
      "Processing row 8:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:24.981718\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             hfQf1Wbw3ZQ\n",
      "duration                                                        43\n",
      "like_count                                                     4.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title            Portion Of Correction  - Kabbalah Moments - No...\n",
      "upload_date                                    2010-11-15 00:00:00\n",
      "view_count                                                   181.0\n",
      "Name: 8, dtype: object\n",
      "Processing row 9:\n",
      "categories                                               Education\n",
      "channel_id                                UC4avQL0dz2oTQtJqXyVfe8g\n",
      "crawl_date                              2019-11-17 12:43:25.695334\n",
      "description      http://bit.ly/km-Kabbalah-Course / Excerpt fro...\n",
      "dislike_count                                                  0.0\n",
      "display_id                                             BPeez_ocl40\n",
      "duration                                                       145\n",
      "like_count                                                     6.0\n",
      "tags             daily,kabbalah,lesson,moments,michael,laitman,...\n",
      "title                 Night - Kabbalah Moments - November 14, 2010\n",
      "upload_date                                    2010-11-15 00:00:00\n",
      "view_count                                                   247.0\n",
      "Name: 9, dtype: object\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     content \u001b[38;5;241m=\u001b[39m bart_classification(combined_text, content_labels, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurpose\u001b[39m\u001b[38;5;124m'\u001b[39m: purpose, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m: level, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: content})\n\u001b[0;32m---> 15\u001b[0m df_education[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurpose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_education\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassify_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mclassify_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n\u001b[1;32m      8\u001b[0m combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m purpose \u001b[38;5;241m=\u001b[39m \u001b[43mbart_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpurpose_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m level \u001b[38;5;241m=\u001b[39m bart_classification(combined_text, level_labels, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m content \u001b[38;5;241m=\u001b[39m bart_classification(combined_text, content_labels, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mbart_classification\u001b[0;34m(text, candidate_labels, multi_label, plot)\u001b[0m\n\u001b[1;32m     11\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize the zero-shot classifier with GPU support\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero-shot-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-large-mnli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m result \u001b[38;5;241m=\u001b[39m classifier(text, candidate_labels, multi_label\u001b[38;5;241m=\u001b[39mmulti_label)\n\u001b[1;32m     17\u001b[0m scores, labels \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m], result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/pipelines/__init__.py:926\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    925\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 926\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    937\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/pipelines/base.py:289\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4218\u001b[0m     (\n\u001b[1;32m   4219\u001b[0m         model,\n\u001b[1;32m   4220\u001b[0m         missing_keys,\n\u001b[1;32m   4221\u001b[0m         unexpected_keys,\n\u001b[1;32m   4222\u001b[0m         mismatched_keys,\n\u001b[1;32m   4223\u001b[0m         offload_index,\n\u001b[1;32m   4224\u001b[0m         error_msgs,\n\u001b[0;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/modeling_utils.py:4540\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4538\u001b[0m             model\u001b[38;5;241m.\u001b[39mapply(model\u001b[38;5;241m.\u001b[39m_initialize_weights)\n\u001b[1;32m   4539\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4540\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4542\u001b[0m \u001b[38;5;66;03m# Set some modules to fp32 if any\u001b[39;00m\n\u001b[1;32m   4543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_in_fp32_modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1029\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1029\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1029\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1029\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1029\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1029\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1030\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   1029\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[0;32m-> 1030\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/modeling_utils.py:1912\u001b[0m, in \u001b[0;36mPreTrainedModel._initialize_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hf_initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1912\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1913\u001b[0m module\u001b[38;5;241m.\u001b[39m_is_hf_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:761\u001b[0m, in \u001b[0;36mBartPreTrainedModel._init_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    759\u001b[0m         module\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mzero_()\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, nn\u001b[38;5;241m.\u001b[39mEmbedding):\n\u001b[0;32m--> 761\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m         module\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata[module\u001b[38;5;241m.\u001b[39mpadding_idx]\u001b[38;5;241m.\u001b[39mzero_()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def classify_row(row):\n",
    "    index = row.name\n",
    "    \n",
    "    if index % 1 == 0:\n",
    "        print(f\"Processing row {index}:\")\n",
    "        print(row)\n",
    "    \n",
    "    combined_text = f\"{row['title']} {row['tags'].replace(',', ', ')}\"\n",
    "    purpose = bart_classification(combined_text, purpose_labels, multi_label=True, plot=False)\n",
    "    level = bart_classification(combined_text, level_labels, multi_label=False, plot=False)\n",
    "    content = bart_classification(combined_text, content_labels, multi_label=True, plot=False)\n",
    "    \n",
    "    return pd.Series({'purpose': purpose, 'level': level, 'content': content})\n",
    "\n",
    "df_education[['purpose', 'level', 'content']] = df_education.apply(classify_row, axis=1)\n",
    "\n",
    "print(\"Classification complete.\")\n",
    "\n",
    "file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {file_path}.\")\n",
    "\n",
    "def classify_broad _dataset (batch, categories, on, classifier):\n",
    "texts = batch[on]\n",
    "\n",
    "\n",
    "broad_categories_labels = list (categories.keys())\n",
    "\n",
    "results = classifier (texts, broad _categories_labels)\n",
    "\n",
    "batch[\"broad _category\"] = [res[\"labels\"][Â©] for res in results]\n",
    "\n",
    "batch \"broad _confidence\"] = [res[\"scores\"][0] for res in results]\n",
    "return batch\n",
    "\n",
    "def classify_broad(data, categories, on, classifier, batch _size-16):\n",
    "print (\"Converting to dataset...\")\n",
    "dataset = Dataset. from _pandas(data)\n",
    "print(\"Processing...\")\n",
    "dataset = dataset.map\n",
    "classify_broad _dataset, batched-True, batch_size=batch_size,\n",
    "fn_kwargs-(\"classifier\": classifier, \"categories\": categories, \"on\": on},\n",
    "print(\"Converting back to dataframe...\")\n",
    "Final data - dataset. to pandas return final data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column Unnamed: 0 with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m df_education \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     94\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[11], line 73\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_data\u001b[39m(data, classifier, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m batch: classify_row_batch(\n\u001b[1;32m     78\u001b[0m             batch, classifier, purpose_labels, level_labels, content_labels\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     82\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column Unnamed: 0 with type int64')"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Initialize BART classification pipeline (Assume classifier is a Hugging Face pipeline)\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define categories\n",
    "purpose_labels = [\n",
    "    \"lecture or academic course\", #exercise\n",
    "    #\"study-tips or test preparation\",\n",
    "    \"hacks\", \n",
    "    \"conference\",\n",
    "    \"tutorial or DIY\",\n",
    "    \"interview or Q&A or review\", #FIND BETTER\n",
    "    \"kids content\",\n",
    "    \"entertaining explanation or science popularization\",\n",
    "    \"documentary\" #research based\n",
    "]\n",
    "\n",
    "level_labels = [\n",
    "    \"beginner\",\n",
    "    \"intermediate\",\n",
    "    \"advanced\",\n",
    "]\n",
    "\n",
    "content_labels = [\n",
    "    \"science or technology\",\n",
    "    \"music or art\",\n",
    "    \"photography or videography or filmaking\",\n",
    "    \"gaming\",\n",
    "    \"chess or puzzles or logic\", #riddles\n",
    "    \"religion or spirituality\",\n",
    "    \"phylosophy or ethics\",\n",
    "    \"history or politics\",\n",
    "    \"economics or business\",\n",
    "    \"financial education\",\n",
    "    \"cryptocurrency\",\n",
    "    \"food or cooking\",\n",
    "    \"sport\",\n",
    "    \"health or medicine\",\n",
    "    \"travel\",\n",
    "    \"motivational or personal development\",\n",
    "    \"home repair or renovation\",  \n",
    "    \"beauty or fashion\",\n",
    "    \"programming tools or coding\",\n",
    "    \"foreign language\",\n",
    "    \"sociology or culture\",\n",
    "    \"psychology\",\n",
    "    \"climate or environment\",\n",
    "    \"wildlife or animals or nature\" #segment?\n",
    "]\n",
    "# Custom function to classify each row in a batch\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Extract and structure classification results\n",
    "    purposes = [res['labels'] for res in purpose_results]\n",
    "    levels = [res['labels'][0] for res in level_results]  # single label, take first\n",
    "    contents = [res['labels'] for res in content_results]\n",
    "\n",
    "    batch['purpose'] = purposes\n",
    "    batch['level'] = levels\n",
    "    batch['content'] = contents\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Process function to handle batching in `datasets`\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    print(\"Converting to Dataset...\")\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "    \n",
    "    print(\"Processing in batches...\")\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(\n",
    "            batch, classifier, purpose_labels, level_labels, content_labels\n",
    "        ),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load data\n",
    "df_education = pd.read_csv(\"data/Education_videos_7.csv\")\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save results\n",
    "file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(file_path, index=False)\n",
    "print(f\"Data saved to {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column duration with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 118\u001b[0m\n\u001b[1;32m    115\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Save the classified data\u001b[39;00m\n\u001b[1;32m    121\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 96\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_data\u001b[39m(data, classifier, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m batch: classify_row_batch(\n\u001b[1;32m    101\u001b[0m             batch, classifier, purpose_labels, level_labels, content_labels\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m    105\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column duration with type int64')"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Function to load and preprocess metadata\n",
    "def load_metadata_videos(file_path):\n",
    "    # Load CSV, drop unnecessary column, and remove rows with missing data\n",
    "    return pd.read_csv(file_path).drop(columns=['Unnamed: 0'], errors='ignore').dropna()\n",
    "\n",
    "# Function to classify text using BART and zero-shot classification\n",
    "def bart_classification(text, candidate_labels, multi_label=True, plot=False):\n",
    "    # Determine device (Apple Silicon or CUDA for GPU if available, else CPU)\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"  # Apple Silicon GPU\n",
    "    elif torch.cuda.is_available():\n",
    "        device = \"cuda\"  # CUDA GPU\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    # Initialize the classifier with GPU support\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "    result = classifier(text, candidate_labels, multi_label=multi_label)\n",
    "    \n",
    "    # Sort results by score\n",
    "    scores, labels = result['scores'], result['labels']\n",
    "    sorted_pairs = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n",
    "    scores, labels = zip(*sorted_pairs)\n",
    "\n",
    "    # Thresholding logic to select top labels based on scores\n",
    "    max_score = scores[0]\n",
    "    threshold = max_score * 0.9\n",
    "    top_count = len([score for score in scores if score >= threshold])\n",
    "\n",
    "    if plot:\n",
    "        plot_scores(scores, labels)\n",
    "\n",
    "    # Classification decisions based on scores and multi-label setting\n",
    "    if max_score < 0.3:\n",
    "        return [\"misc\"]\n",
    "    elif top_count == 1:\n",
    "        return [labels[0]]\n",
    "    elif top_count == 2 and multi_label:\n",
    "        return [labels[0], labels[1]]\n",
    "    elif top_count == 3 and multi_label:\n",
    "        return [labels[0], labels[1], labels[2]]\n",
    "    else:\n",
    "        return [\"uncertain\"]\n",
    "\n",
    "# Define labels for different categories\n",
    "purpose_labels = [\n",
    "    \"lecture or academic course\", \"hacks\", \"conference\", \"tutorial or DIY\",\n",
    "    \"interview or Q&A or review\", \"kids content\", \n",
    "    \"entertaining explanation or science popularization\", \"documentary\"\n",
    "]\n",
    "\n",
    "level_labels = [\n",
    "    \"beginner\", \"intermediate\", \"advanced\"\n",
    "]\n",
    "\n",
    "content_labels = [\n",
    "    \"science or technology\", \"music or art\", \"photography or videography or filmaking\",\n",
    "    \"gaming\", \"chess or puzzles or logic\", \"religion or spirituality\",\n",
    "    \"philosophy or ethics\", \"history or politics\", \"economics or business\",\n",
    "    \"financial education\", \"cryptocurrency\", \"food or cooking\", \"sport\",\n",
    "    \"health or medicine\", \"travel\", \"motivational or personal development\",\n",
    "    \"home repair or renovation\", \"beauty or fashion\", \"programming tools or coding\",\n",
    "    \"foreign language\", \"sociology or culture\", \"psychology\", \"climate or environment\",\n",
    "    \"wildlife or animals or nature\"\n",
    "]\n",
    "\n",
    "# Function to classify a batch of rows\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    # Classify texts for each category\n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Extract labels and store results\n",
    "    purposes = [res['labels'] for res in purpose_results]\n",
    "    levels = [res['labels'][0] for res in level_results]  # Single label\n",
    "    contents = [res['labels'] for res in content_results]\n",
    "\n",
    "    batch['purpose'] = purposes\n",
    "    batch['level'] = levels\n",
    "    batch['content'] = contents\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Function to handle classification on the entire dataset in batches\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    print(\"Converting to Dataset...\")\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "    \n",
    "    print(\"Processing in batches...\")\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(\n",
    "            batch, classifier, purpose_labels, level_labels, content_labels\n",
    "        ),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)\n",
    "\n",
    "# Initialize classifier pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save the classified data\n",
    "output_file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column duration with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Save the classified data\u001b[39;00m\n\u001b[1;32m    117\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 91\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m     data[col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data[col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m batch: classify_row_batch(\n\u001b[1;32m     96\u001b[0m         batch, classifier, purpose_labels, level_labels, content_labels\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m    100\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column duration with type int64')"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Function to load and preprocess metadata\n",
    "def load_metadata_videos(file_path):\n",
    "    # Load CSV, drop unnecessary column, and remove rows with missing data\n",
    "    return pd.read_csv(file_path).drop(columns=['Unnamed: 0'], errors='ignore').dropna()\n",
    "\n",
    "# Function to classify text using BART and zero-shot classification\n",
    "def bart_classification(text, candidate_labels, multi_label=True, plot=False):\n",
    "    # Determine device (Apple Silicon or CUDA for GPU if available, else CPU)\n",
    "    device = 0 if torch.cuda.is_available() else -1  # CUDA for GPU if available, else CPU\n",
    "\n",
    "    # Initialize the classifier with GPU support\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "    result = classifier(text, candidate_labels, multi_label=multi_label)\n",
    "    \n",
    "    # Sort results by score\n",
    "    scores, labels = result['scores'], result['labels']\n",
    "    sorted_pairs = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n",
    "    scores, labels = zip(*sorted_pairs)\n",
    "\n",
    "    # Thresholding logic to select top labels based on scores\n",
    "    max_score = scores[0]\n",
    "    threshold = max_score * 0.9\n",
    "    top_count = len([score for score in scores if score >= threshold])\n",
    "\n",
    "    # Classification decisions based on scores and multi-label setting\n",
    "    if max_score < 0.3:\n",
    "        return [\"misc\"]\n",
    "    elif top_count == 1:\n",
    "        return [labels[0]]\n",
    "    elif top_count == 2 and multi_label:\n",
    "        return [labels[0], labels[1]]\n",
    "    elif top_count == 3 and multi_label:\n",
    "        return [labels[0], labels[1], labels[2]]\n",
    "    else:\n",
    "        return [\"uncertain\"]\n",
    "\n",
    "# Define labels for different categories\n",
    "purpose_labels = [\n",
    "    \"lecture or academic course\", \"hacks\", \"conference\", \"tutorial or DIY\",\n",
    "    \"interview or Q&A or review\", \"kids content\", \n",
    "    \"entertaining explanation or science popularization\", \"documentary\"\n",
    "]\n",
    "\n",
    "level_labels = [\n",
    "    \"beginner\", \"intermediate\", \"advanced\"\n",
    "]\n",
    "\n",
    "content_labels = [\n",
    "    \"science or technology\", \"music or art\", \"photography or videography or filmmaking\",\n",
    "    \"gaming\", \"chess or puzzles or logic\", \"religion or spirituality\",\n",
    "    \"philosophy or ethics\", \"history or politics\", \"economics or business\",\n",
    "    \"financial education\", \"cryptocurrency\", \"food or cooking\", \"sport\",\n",
    "    \"health or medicine\", \"travel\", \"motivational or personal development\",\n",
    "    \"home repair or renovation\", \"beauty or fashion\", \"programming tools or coding\",\n",
    "    \"foreign language\", \"sociology or culture\", \"psychology\", \"climate or environment\",\n",
    "    \"wildlife or animals or nature\"\n",
    "]\n",
    "\n",
    "# Function to classify a batch of rows\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    # Classify texts for each category\n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Extract labels and store results\n",
    "    purposes = [res['labels'] for res in purpose_results]\n",
    "    levels = [res['labels'][0] for res in level_results]  # Single label\n",
    "    contents = [res['labels'] for res in content_results]\n",
    "\n",
    "    batch['purpose'] = purposes\n",
    "    batch['level'] = levels\n",
    "    batch['content'] = contents\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Function to handle classification on the entire dataset in batches\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    # Check for dtype issues and convert incompatible columns\n",
    "    for col in data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    print(\"Converting to Dataset...\")\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "    \n",
    "    print(\"Processing in batches...\")\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(\n",
    "            batch, classifier, purpose_labels, level_labels, content_labels\n",
    "        ),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)\n",
    "\n",
    "# Initialize classifier pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1  # Ensure GPU use if available\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save the classified data\n",
    "output_file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Save the classified data\u001b[39;00m\n\u001b[1;32m    110\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[14], line 85\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m data \u001b[38;5;241m=\u001b[39m clean_data_types(data)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Should now handle all columns\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Apply classification in batches\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load CSV and drop unnamed or null columns\n",
    "def load_metadata_videos(file_path):\n",
    "    df = pd.read_csv(file_path).dropna()\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # Drop unnamed columns\n",
    "    return df\n",
    "\n",
    "# Check data types and convert incompatible types for `Dataset`\n",
    "def clean_data_types(df):\n",
    "    # Convert integer columns to `float` to avoid Arrow errors\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[col]):\n",
    "            df[col] = df[col].astype('float')\n",
    "        elif pd.api.types.is_object_dtype(df[col]):\n",
    "            df[col] = df[col].astype('string')  # Ensure all text columns are strings\n",
    "    return df\n",
    "\n",
    "# Function to classify text using BART and zero-shot classification\n",
    "def bart_classification(text, candidate_labels, multi_label=True):\n",
    "    device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "\n",
    "    # Initialize the classifier with GPU support\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "    result = classifier(text, candidate_labels, multi_label=multi_label)\n",
    "    \n",
    "    # Sort and threshold scores\n",
    "    scores, labels = result['scores'], result['labels']\n",
    "    sorted_pairs = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n",
    "    scores, labels = zip(*sorted_pairs)\n",
    "    \n",
    "    max_score = scores[0]\n",
    "    threshold = max_score * 0.9\n",
    "    top_count = len([score for score in scores if score >= threshold])\n",
    "\n",
    "    # Classification logic based on score thresholds\n",
    "    if max_score < 0.3:\n",
    "        return [\"misc\"]\n",
    "    elif top_count == 1:\n",
    "        return [labels[0]]\n",
    "    elif top_count == 2 and multi_label:\n",
    "        return [labels[0], labels[1]]\n",
    "    elif top_count == 3 and multi_label:\n",
    "        return [labels[0], labels[1], labels[2]]\n",
    "    else:\n",
    "        return [\"uncertain\"]\n",
    "\n",
    "# Define labels for different categories\n",
    "purpose_labels = [\"lecture or academic course\", \"hacks\", \"conference\", \"tutorial or DIY\",\n",
    "                  \"interview or Q&A or review\", \"kids content\", \"entertaining explanation or science popularization\",\n",
    "                  \"documentary\"]\n",
    "level_labels = [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "content_labels = [\"science or technology\", \"music or art\", \"photography or videography or filmmaking\", \"gaming\",\n",
    "                  \"chess or puzzles or logic\", \"religion or spirituality\", \"philosophy or ethics\", \"history or politics\",\n",
    "                  \"economics or business\", \"financial education\", \"cryptocurrency\", \"food or cooking\", \"sport\",\n",
    "                  \"health or medicine\", \"travel\", \"motivational or personal development\", \"home repair or renovation\",\n",
    "                  \"beauty or fashion\", \"programming tools or coding\", \"foreign language\", \"sociology or culture\",\n",
    "                  \"psychology\", \"climate or environment\", \"wildlife or animals or nature\"]\n",
    "\n",
    "# Classify each batch row by row\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Store results\n",
    "    batch['purpose'] = [res['labels'] for res in purpose_results]\n",
    "    batch['level'] = [res['labels'][0] for res in level_results]  # single label\n",
    "    batch['content'] = [res['labels'] for res in content_results]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Full classification process with data type cleaning\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    # Clean data types for compatibility with Dataset\n",
    "    data = clean_data_types(data)\n",
    "    \n",
    "    print(\"Converting to Dataset...\")\n",
    "    dataset = Dataset.from_pandas(data)  # Should now handle all columns\n",
    "    print(\"Processing in batches...\")\n",
    "    \n",
    "    # Apply classification in batches\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)\n",
    "\n",
    "# Initialize classifier pipeline with device specified\n",
    "device = 0 if torch.cuda.is_available() else -1  # Ensure GPU use if available\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save the classified data\n",
    "output_file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping unnecessary columns and converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Save the classified data\u001b[39;00m\n\u001b[1;32m    105\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[15], line 80\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m data \u001b[38;5;241m=\u001b[39m preprocess_data(data, columns_to_drop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Drop `duration` or any other columns causing errors\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Convert to Dataset\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Apply classification in batches\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load CSV and drop unnamed or null columns\n",
    "def load_metadata_videos(file_path):\n",
    "    df = pd.read_csv(file_path).dropna()\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # Drop unnamed columns\n",
    "    return df\n",
    "\n",
    "# Drop unnecessary columns to avoid Arrow errors (like `duration`)\n",
    "def preprocess_data(df, columns_to_drop):\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')  # Drop specified columns if they exist\n",
    "    return df\n",
    "\n",
    "# Function to classify text using BART and zero-shot classification\n",
    "def bart_classification(text, candidate_labels, multi_label=True):\n",
    "    device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "\n",
    "    # Initialize the classifier with GPU support\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "    result = classifier(text, candidate_labels, multi_label=multi_label)\n",
    "    \n",
    "    # Sort and threshold scores\n",
    "    scores, labels = result['scores'], result['labels']\n",
    "    sorted_pairs = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n",
    "    scores, labels = zip(*sorted_pairs)\n",
    "    \n",
    "    max_score = scores[0]\n",
    "    threshold = max_score * 0.9\n",
    "    top_count = len([score for score in scores if score >= threshold])\n",
    "\n",
    "    # Classification logic based on score thresholds\n",
    "    if max_score < 0.3:\n",
    "        return [\"misc\"]\n",
    "    elif top_count == 1:\n",
    "        return [labels[0]]\n",
    "    elif top_count == 2 and multi_label:\n",
    "        return [labels[0], labels[1]]\n",
    "    elif top_count == 3 and multi_label:\n",
    "        return [labels[0], labels[1], labels[2]]\n",
    "    else:\n",
    "        return [\"uncertain\"]\n",
    "\n",
    "# Define labels for different categories\n",
    "purpose_labels = [\"lecture or academic course\", \"hacks\", \"conference\", \"tutorial or DIY\",\n",
    "                  \"interview or Q&A or review\", \"kids content\", \"entertaining explanation or science popularization\",\n",
    "                  \"documentary\"]\n",
    "level_labels = [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "content_labels = [\"science or technology\", \"music or art\", \"photography or videography or filmmaking\", \"gaming\",\n",
    "                  \"chess or puzzles or logic\", \"religion or spirituality\", \"philosophy or ethics\", \"history or politics\",\n",
    "                  \"economics or business\", \"financial education\", \"cryptocurrency\", \"food or cooking\", \"sport\",\n",
    "                  \"health or medicine\", \"travel\", \"motivational or personal development\", \"home repair or renovation\",\n",
    "                  \"beauty or fashion\", \"programming tools or coding\", \"foreign language\", \"sociology or culture\",\n",
    "                  \"psychology\", \"climate or environment\", \"wildlife or animals or nature\"]\n",
    "\n",
    "# Classify each batch row by row\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Store results\n",
    "    batch['purpose'] = [res['labels'] for res in purpose_results]\n",
    "    batch['level'] = [res['labels'][0] for res in level_results]  # single label\n",
    "    batch['content'] = [res['labels'] for res in content_results]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Full classification process with data type cleaning\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    print(\"Dropping unnecessary columns and converting to Dataset...\")\n",
    "    data = preprocess_data(data, columns_to_drop=['duration'])  # Drop `duration` or any other columns causing errors\n",
    "    \n",
    "    # Convert to Dataset\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "    print(\"Processing in batches...\")\n",
    "    \n",
    "    # Apply classification in batches\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)\n",
    "\n",
    "# Initialize classifier pipeline with device specified\n",
    "device = 0 if torch.cuda.is_available() else -1  # Ensure GPU use if available\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save the classified data\n",
    "output_file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Save the classified data\u001b[39;00m\n\u001b[1;32m     98\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 73\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Select only 'title' and 'tags' columns and convert to Dataset\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Apply classification in batches\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load CSV and select only necessary columns\n",
    "def load_metadata_videos(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=['title', 'tags']).dropna()  # Only load 'title' and 'tags' columns\n",
    "    return df\n",
    "\n",
    "# Function to classify text using BART and zero-shot classification\n",
    "def bart_classification(text, candidate_labels, multi_label=True):\n",
    "    device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "\n",
    "    # Initialize the classifier with GPU support\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "    result = classifier(text, candidate_labels, multi_label=multi_label)\n",
    "    \n",
    "    # Sort and threshold scores\n",
    "    scores, labels = result['scores'], result['labels']\n",
    "    sorted_pairs = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n",
    "    scores, labels = zip(*sorted_pairs)\n",
    "    \n",
    "    max_score = scores[0]\n",
    "    threshold = max_score * 0.9\n",
    "    top_count = len([score for score in scores if score >= threshold])\n",
    "\n",
    "    # Classification logic based on score thresholds\n",
    "    if max_score < 0.3:\n",
    "        return [\"misc\"]\n",
    "    elif top_count == 1:\n",
    "        return [labels[0]]\n",
    "    elif top_count == 2 and multi_label:\n",
    "        return [labels[0], labels[1]]\n",
    "    elif top_count == 3 and multi_label:\n",
    "        return [labels[0], labels[1], labels[2]]\n",
    "    else:\n",
    "        return [\"uncertain\"]\n",
    "\n",
    "# Define labels for different categories\n",
    "purpose_labels = [\"lecture or academic course\", \"hacks\", \"conference\", \"tutorial or DIY\",\n",
    "                  \"interview or Q&A or review\", \"kids content\", \"entertaining explanation or science popularization\",\n",
    "                  \"documentary\"]\n",
    "level_labels = [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "content_labels = [\"science or technology\", \"music or art\", \"photography or videography or filmmaking\", \"gaming\",\n",
    "                  \"chess or puzzles or logic\", \"religion or spirituality\", \"philosophy or ethics\", \"history or politics\",\n",
    "                  \"economics or business\", \"financial education\", \"cryptocurrency\", \"food or cooking\", \"sport\",\n",
    "                  \"health or medicine\", \"travel\", \"motivational or personal development\", \"home repair or renovation\",\n",
    "                  \"beauty or fashion\", \"programming tools or coding\", \"foreign language\", \"sociology or culture\",\n",
    "                  \"psychology\", \"climate or environment\", \"wildlife or animals or nature\"]\n",
    "\n",
    "# Classify each batch row by row\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Store results\n",
    "    batch['purpose'] = [res['labels'] for res in purpose_results]\n",
    "    batch['level'] = [res['labels'][0] for res in level_results]  # single label\n",
    "    batch['content'] = [res['labels'] for res in content_results]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Full classification process with only selected columns\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    print(\"Converting to Dataset...\")\n",
    "    \n",
    "    # Select only 'title' and 'tags' columns and convert to Dataset\n",
    "    dataset = Dataset.from_pandas(data[['title', 'tags']])\n",
    "    print(\"Processing in batches...\")\n",
    "    \n",
    "    # Apply classification in batches\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)\n",
    "\n",
    "# Initialize classifier pipeline with device specified\n",
    "device = 0 if torch.cuda.is_available() else -1  # Ensure GPU use if available\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save the classified data\n",
    "output_file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Dataset...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Run classification\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m df_education \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Save the classified data\u001b[39;00m\n\u001b[1;32m     71\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Education_videos_7_BART.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 46\u001b[0m, in \u001b[0;36mclassify_data\u001b[0;34m(data, classifier, batch_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Select only 'title' and 'tags' columns and convert to Dataset\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing in batches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Apply classification in batches\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:618\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_definitely_zero_copy(c\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m--> 618\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(convert_column, c, f))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load only the necessary columns ('title' and 'tags') and ensure they are strings\n",
    "def load_metadata_videos(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=['title', 'tags']).dropna()\n",
    "    df['title'] = df['title'].astype(str)  # Convert to string to avoid type issues\n",
    "    df['tags'] = df['tags'].astype(str)    # Convert to string to avoid type issues\n",
    "    return df\n",
    "\n",
    "# Define labels for different categories\n",
    "purpose_labels = [\"lecture or academic course\", \"hacks\", \"conference\", \"tutorial or DIY\",\n",
    "                  \"interview or Q&A or review\", \"kids content\", \"entertaining explanation or science popularization\",\n",
    "                  \"documentary\"]\n",
    "level_labels = [\"beginner\", \"intermediate\", \"advanced\"]\n",
    "content_labels = [\"science or technology\", \"music or art\", \"photography or videography or filmmaking\", \"gaming\",\n",
    "                  \"chess or puzzles or logic\", \"religion or spirituality\", \"philosophy or ethics\", \"history or politics\",\n",
    "                  \"economics or business\", \"financial education\", \"cryptocurrency\", \"food or cooking\", \"sport\",\n",
    "                  \"health or medicine\", \"travel\", \"motivational or personal development\", \"home repair or renovation\",\n",
    "                  \"beauty or fashion\", \"programming tools or coding\", \"foreign language\", \"sociology or culture\",\n",
    "                  \"psychology\", \"climate or environment\", \"wildlife or animals or nature\"]\n",
    "\n",
    "# Classify each row in batches\n",
    "def classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels):\n",
    "    texts = [f\"{title} {tags.replace(',', ', ')}\" for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    purpose_results = classifier(texts, purpose_labels, multi_label=True)\n",
    "    level_results = classifier(texts, level_labels, multi_label=False)\n",
    "    content_results = classifier(texts, content_labels, multi_label=True)\n",
    "\n",
    "    # Store results\n",
    "    batch['purpose'] = [res['labels'] for res in purpose_results]\n",
    "    batch['level'] = [res['labels'][0] for res in level_results]  # single label\n",
    "    batch['content'] = [res['labels'] for res in content_results]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Full classification process with only selected columns\n",
    "def classify_data(data, classifier, batch_size=32):\n",
    "    print(\"Converting to Dataset...\")\n",
    "    \n",
    "    # Select only 'title' and 'tags' columns and convert to Dataset\n",
    "    dataset = Dataset.from_pandas(data[['title', 'tags']])\n",
    "    print(\"Processing in batches...\")\n",
    "    \n",
    "    # Apply classification in batches\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: classify_row_batch(batch, classifier, purpose_labels, level_labels, content_labels),\n",
    "        batched=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"Converting back to DataFrame...\")\n",
    "    return dataset.to_pandas()\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"data/Education_videos_7.csv\"\n",
    "df_education = load_metadata_videos(file_path)\n",
    "\n",
    "# Initialize classifier pipeline with device specified\n",
    "device = 0 if torch.cuda.is_available() else -1  # Ensure GPU use if available\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Run classification\n",
    "df_education = classify_data(df_education, classifier, batch_size=32)\n",
    "\n",
    "# Save the classified data\n",
    "output_file_path = \"data/Education_videos_7_BART.csv\"\n",
    "df_education.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "('Input object was not a NumPy array', 'Conversion failed for column categories with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m df_education[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_education[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Convert the pandas DataFrame to a HuggingFace Dataset\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Instantiate the zero-shot classification model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Set to 0 if using GPU, or -1 for CPU\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Input object was not a NumPy array', 'Conversion failed for column categories with type object')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "# Read in the data\n",
    "df_education = pd.read_csv(\"data/Education_videos_7.csv\")\n",
    "\n",
    "# Clean the dataset (remove unnecessary columns if needed)\n",
    "df_education = df_education.drop(columns=['Unnamed: 0', 'duration'], errors='ignore')\n",
    "\n",
    "# Ensure text columns are strings\n",
    "df_education['title'] = df_education['title'].astype(str)\n",
    "df_education['tags'] = df_education['tags'].astype(str)\n",
    "\n",
    "# Convert the pandas DataFrame to a HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df_education)\n",
    "\n",
    "# Instantiate the zero-shot classification model\n",
    "device = 0  # Set to 0 if using GPU, or -1 for CPU\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Define label sets for classification\n",
    "purpose_labels = ['education', 'entertainment', 'news', 'tutorial']\n",
    "level_labels = ['beginner', 'intermediate', 'advanced']\n",
    "content_labels = ['theory', 'practical', 'case_study', 'review']\n",
    "\n",
    "# Function to classify a batch of data\n",
    "def classify_batch(batch):\n",
    "    # Combine the title and tags for classification\n",
    "    combined_texts = [title + \" \" + tags for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    # Perform classification for each label in batch\n",
    "    purpose_results = classifier(combined_texts, candidate_labels=purpose_labels)\n",
    "    level_results = classifier(combined_texts, candidate_labels=level_labels)\n",
    "    content_results = classifier(combined_texts, candidate_labels=content_labels)\n",
    "    \n",
    "    # Extract the top label for each classification\n",
    "    batch['purpose'] = [result['labels'][0] for result in purpose_results]\n",
    "    batch['level'] = [result['labels'][0] for result in level_results]\n",
    "    batch['content'] = [result['labels'][0] for result in content_results]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Use the map function to apply classify_batch in parallel (default batch_size is large enough for parallel processing)\n",
    "dataset = dataset.map(classify_batch, batched=True)\n",
    "\n",
    "# Convert the dataset back to a pandas DataFrame\n",
    "df_classified = dataset.to_pandas()\n",
    "\n",
    "# Save the final result to a CSV file\n",
    "output_file_path = \"data/Education_videos_7_BART_map.csv\"\n",
    "df_classified.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Batch classification complete. Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "('Input object was not a NumPy array', 'Conversion failed for column categories with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m df_education[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_education[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mstr\u001b[39m(x))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Convert the pandas DataFrame to a HuggingFace Dataset\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_education\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Instantiate the zero-shot classification model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Set to 0 if using GPU, or -1 for CPU\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/datasets/table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_env/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Input object was not a NumPy array', 'Conversion failed for column categories with type object')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import pipeline\n",
    "\n",
    "# Read in the data\n",
    "df_education = pd.read_csv(\"data/Education_videos_7.csv\")\n",
    "\n",
    "# Clean the dataset (remove unnecessary columns if needed)\n",
    "df_education = df_education.drop(columns=['Unnamed: 0', 'duration'], errors='ignore')\n",
    "\n",
    "# Ensure text columns are strings\n",
    "df_education['title'] = df_education['title'].astype(str)\n",
    "df_education['tags'] = df_education['tags'].astype(str)\n",
    "\n",
    "# Ensure there are no complex or mixed data types\n",
    "df_education['tags'] = df_education['tags'].apply(lambda x: str(x))\n",
    "\n",
    "# Convert the pandas DataFrame to a HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df_education)\n",
    "\n",
    "# Instantiate the zero-shot classification model\n",
    "device = 0  # Set to 0 if using GPU, or -1 for CPU\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Define label sets for classification\n",
    "purpose_labels = ['education', 'entertainment', 'news', 'tutorial']\n",
    "level_labels = ['beginner', 'intermediate', 'advanced']\n",
    "content_labels = ['theory', 'practical', 'case_study', 'review']\n",
    "\n",
    "# Function to classify a batch of data\n",
    "def classify_batch(batch):\n",
    "    # Combine the title and tags for classification\n",
    "    combined_texts = [title + \" \" + tags for title, tags in zip(batch['title'], batch['tags'])]\n",
    "    \n",
    "    # Perform classification for each label in batch\n",
    "    purpose_results = classifier(combined_texts, candidate_labels=purpose_labels)\n",
    "    level_results = classifier(combined_texts, candidate_labels=level_labels)\n",
    "    content_results = classifier(combined_texts, candidate_labels=content_labels)\n",
    "    \n",
    "    # Extract the top label for each classification\n",
    "    batch['purpose'] = [result['labels'][0] for result in purpose_results]\n",
    "    batch['level'] = [result['labels'][0] for result in level_results]\n",
    "    batch['content'] = [result['labels'][0] for result in content_results]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Use the map function to apply classify_batch in parallel (default batch_size is large enough for parallel processing)\n",
    "dataset = dataset.map(classify_batch, batched=True)\n",
    "\n",
    "# Convert the dataset back to a pandas DataFrame\n",
    "df_classified = dataset.to_pandas()\n",
    "\n",
    "# Save the final result to a CSV file\n",
    "output_file_path = \"data/Education_videos_7_BART_map.csv\"\n",
    "df_classified.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Batch classification complete. Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
